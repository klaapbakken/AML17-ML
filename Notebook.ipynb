{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from operator import itemgetter\n",
    "import json\n",
    "\n",
    "path = './/Data//Emails'\n",
    "dict_path = './/Data//English Words'\n",
    "name_path = './/Data//English Names'\n",
    "additional_path  = './/Data//Additional'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Subject: great nnews  hello , welcome to medzo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Subject: here ' s a hot play in motion  homela...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>Subject: save your money buy getting this thin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>Subject: save your money buy getting this thin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>Subject: brighten those teeth  get your  teeth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>Subject: fpa notice : ebay misrepresentation o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>Subject: search engine position  be the very f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>Subject: only our software is guaranteed 100 %...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22</td>\n",
       "      <td>Subject: top - level logo and business identit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24</td>\n",
       "      <td>Subject: rely on us for your online prescripti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25</td>\n",
       "      <td>Subject: guzzle like a fountain  spur m rocks ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26</td>\n",
       "      <td>Subject: are you losing ? the answer would ama...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28</td>\n",
       "      <td>Subject: 25 mg did thhe trick  ho receivable w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>29</td>\n",
       "      <td>Subject: save your money buy getting this thin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30</td>\n",
       "      <td>Subject: want to accept credit cards ? 1264322...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32</td>\n",
       "      <td>Subject: [ ilug ] guaranteed to lose 10 - 12 l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>33</td>\n",
       "      <td>Subject: re : just to her . . .  mdaemon has i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>34</td>\n",
       "      <td>Subject: ms 2003 software titles available for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>35</td>\n",
       "      <td>Subject: failure notice  hi . this is the qmai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>36</td>\n",
       "      <td>Subject: claim your free $ 1000 home depot gif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>37</td>\n",
       "      <td>Subject: perfect logo charset = koi 8 - r \" &gt; ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>39</td>\n",
       "      <td>Subject: extra time - last 5 - 10 times longer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>40</td>\n",
       "      <td>Subject: get the best price on your next car !...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>41</td>\n",
       "      <td>Subject: bro check out this awesome new produc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>42</td>\n",
       "      <td>Subject: hidden gems help get a leg up on the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>43</td>\n",
       "      <td>Subject: 10 minutes before sex , lasts for 24 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>5689</td>\n",
       "      <td>Subject: tanya ' s trip to stanford  shirley ,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>5691</td>\n",
       "      <td>Subject: numbers for sharad agnihotri  hi dale...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>5693</td>\n",
       "      <td>Subject: re : petrochem desk  yes , i will hav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>5694</td>\n",
       "      <td>Subject: ljm model  ryan :  this is the update...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>5697</td>\n",
       "      <td>Subject: research group , recruiting  celeste ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>5698</td>\n",
       "      <td>Subject: schedule and more . .  dr . kaminski ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>5699</td>\n",
       "      <td>Subject: re : message from ken rice  vince :  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>5700</td>\n",
       "      <td>Subject: re : exploration data as the root of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>5701</td>\n",
       "      <td>Subject: rendez - vous reporter : sunday 3 rd ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>5702</td>\n",
       "      <td>Subject: dr . michelle foss - energy institute...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>5703</td>\n",
       "      <td>Subject: rice / enron finance seminar series  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>5704</td>\n",
       "      <td>Subject: storage model security  stinson ,  i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>5705</td>\n",
       "      <td>Subject: re : meeting w kevin hannon  vince an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>5706</td>\n",
       "      <td>Subject: e - mail and voicemail retention poli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>5707</td>\n",
       "      <td>Subject: approval is overdue : access request ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>5709</td>\n",
       "      <td>Subject: agenda for larry thorne ' s presentat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>5710</td>\n",
       "      <td>Subject: raptors  here is the most recent vers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>5712</td>\n",
       "      <td>Subject: 2 - survey / information email 5 - 7 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>5713</td>\n",
       "      <td>Subject: promotion  vince , i want to congratu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010</th>\n",
       "      <td>5714</td>\n",
       "      <td>Subject: re : petronas benchmarking visit  fyi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4011</th>\n",
       "      <td>5715</td>\n",
       "      <td>Subject: request submitted : access request fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>5716</td>\n",
       "      <td>Subject: * special notification * aurora versi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4013</th>\n",
       "      <td>5717</td>\n",
       "      <td>Subject: fwd : update  return - path :  receiv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4014</th>\n",
       "      <td>5718</td>\n",
       "      <td>Subject: altos na gas model  kim , i know you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4015</th>\n",
       "      <td>5720</td>\n",
       "      <td>Subject: re : visit to houston  fyi  - - - - -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>5722</td>\n",
       "      <td>Subject: re : vacation  vince :  i just found ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017</th>\n",
       "      <td>5724</td>\n",
       "      <td>Subject: re : receipts from visit  jim ,  than...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4018</th>\n",
       "      <td>5725</td>\n",
       "      <td>Subject: re : enron case study update  wow ! a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019</th>\n",
       "      <td>5726</td>\n",
       "      <td>Subject: re : interest  david ,  please , call...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>5727</td>\n",
       "      <td>Subject: news : aurora 5 . 2 update  aurora ve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4021 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  spam\n",
       "0        0  Subject: naturally irresistible your corporate...     1\n",
       "1        2  Subject: unbelievable new homes made easy  im ...     1\n",
       "2        3  Subject: 4 color printing special  request add...     1\n",
       "3        4  Subject: do not have money , get software cds ...     1\n",
       "4        5  Subject: great nnews  hello , welcome to medzo...     1\n",
       "5        6  Subject: here ' s a hot play in motion  homela...     1\n",
       "6        9  Subject: save your money buy getting this thin...     1\n",
       "7       11  Subject: save your money buy getting this thin...     1\n",
       "8       12  Subject: brighten those teeth  get your  teeth...     1\n",
       "9       14  Subject: fpa notice : ebay misrepresentation o...     1\n",
       "10      15  Subject: search engine position  be the very f...     1\n",
       "11      16  Subject: only our software is guaranteed 100 %...     1\n",
       "12      22  Subject: top - level logo and business identit...     1\n",
       "13      24  Subject: rely on us for your online prescripti...     1\n",
       "14      25  Subject: guzzle like a fountain  spur m rocks ...     1\n",
       "15      26  Subject: are you losing ? the answer would ama...     1\n",
       "16      28  Subject: 25 mg did thhe trick  ho receivable w...     1\n",
       "17      29  Subject: save your money buy getting this thin...     1\n",
       "18      30  Subject: want to accept credit cards ? 1264322...     1\n",
       "19      32  Subject: [ ilug ] guaranteed to lose 10 - 12 l...     1\n",
       "20      33  Subject: re : just to her . . .  mdaemon has i...     1\n",
       "21      34  Subject: ms 2003 software titles available for...     1\n",
       "22      35  Subject: failure notice  hi . this is the qmai...     1\n",
       "23      36  Subject: claim your free $ 1000 home depot gif...     1\n",
       "24      37  Subject: perfect logo charset = koi 8 - r \" > ...     1\n",
       "25      39  Subject: extra time - last 5 - 10 times longer...     1\n",
       "26      40  Subject: get the best price on your next car !...     1\n",
       "27      41  Subject: bro check out this awesome new produc...     1\n",
       "28      42  Subject: hidden gems help get a leg up on the ...     1\n",
       "29      43  Subject: 10 minutes before sex , lasts for 24 ...     1\n",
       "...    ...                                                ...   ...\n",
       "3991  5689  Subject: tanya ' s trip to stanford  shirley ,...     0\n",
       "3992  5691  Subject: numbers for sharad agnihotri  hi dale...     0\n",
       "3993  5693  Subject: re : petrochem desk  yes , i will hav...     0\n",
       "3994  5694  Subject: ljm model  ryan :  this is the update...     0\n",
       "3995  5697  Subject: research group , recruiting  celeste ...     0\n",
       "3996  5698  Subject: schedule and more . .  dr . kaminski ...     0\n",
       "3997  5699  Subject: re : message from ken rice  vince :  ...     0\n",
       "3998  5700  Subject: re : exploration data as the root of ...     0\n",
       "3999  5701  Subject: rendez - vous reporter : sunday 3 rd ...     0\n",
       "4000  5702  Subject: dr . michelle foss - energy institute...     0\n",
       "4001  5703  Subject: rice / enron finance seminar series  ...     0\n",
       "4002  5704  Subject: storage model security  stinson ,  i ...     0\n",
       "4003  5705  Subject: re : meeting w kevin hannon  vince an...     0\n",
       "4004  5706  Subject: e - mail and voicemail retention poli...     0\n",
       "4005  5707  Subject: approval is overdue : access request ...     0\n",
       "4006  5709  Subject: agenda for larry thorne ' s presentat...     0\n",
       "4007  5710  Subject: raptors  here is the most recent vers...     0\n",
       "4008  5712  Subject: 2 - survey / information email 5 - 7 ...     0\n",
       "4009  5713  Subject: promotion  vince , i want to congratu...     0\n",
       "4010  5714  Subject: re : petronas benchmarking visit  fyi...     0\n",
       "4011  5715  Subject: request submitted : access request fo...     0\n",
       "4012  5716  Subject: * special notification * aurora versi...     0\n",
       "4013  5717  Subject: fwd : update  return - path :  receiv...     0\n",
       "4014  5718  Subject: altos na gas model  kim , i know you ...     0\n",
       "4015  5720  Subject: re : visit to houston  fyi  - - - - -...     0\n",
       "4016  5722  Subject: re : vacation  vince :  i just found ...     0\n",
       "4017  5724  Subject: re : receipts from visit  jim ,  than...     0\n",
       "4018  5725  Subject: re : enron case study update  wow ! a...     0\n",
       "4019  5726  Subject: re : interest  david ,  please , call...     0\n",
       "4020  5727  Subject: news : aurora 5 . 2 update  aurora ve...     0\n",
       "\n",
       "[4021 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(os.path.join(path,'emails.train.csv'))\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible features: \n",
    "* Word frequency\n",
    " * Each element of the vector indicates frequency of respective word. Occurances divided by total words\n",
    "* Length frequency\n",
    " * Each element of the vector indicates frequency of word with length i. Occurances dived by total words\n",
    "* Total number of words\n",
    " * Numeric value\n",
    "* Total number of letters\n",
    " * Numeric value\n",
    "* Number of non-alphabet characeters in subject\n",
    "* Number of non-alphabet characters in body\n",
    "* Indicators in subject\n",
    " * Reply, forward ..\n",
    "* Personal greeting\n",
    "* Presence of personal names\n",
    "* Number of grammatically incorrect words\n",
    "* Number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creates dictionary of the form {word(str):number(int)} for a single piece of text\n",
    "def word_split(text):\n",
    "    word_dict = {}\n",
    "    current_word = str()\n",
    "    for i in range(len(text)):\n",
    "        if text[i].isalpha():\n",
    "            current_word += text[i]\n",
    "            continue\n",
    "        else:\n",
    "            if current_word:\n",
    "                if current_word in word_dict:\n",
    "                    word_dict[current_word] += 1\n",
    "                else:\n",
    "                    word_dict[current_word] = 1\n",
    "                current_word = str()\n",
    "            else:\n",
    "                continue\n",
    "    return word_dict\n",
    "\n",
    "#Creates a list of all words in the data set\n",
    "def local_words(text_list):\n",
    "    local_word_list = []\n",
    "    for i in range(len(text_list)):\n",
    "        text = text_list.iloc[i]\n",
    "        word_dict = word_split(text)\n",
    "        for word in word_dict:\n",
    "            local_word_list.append(word)\n",
    "    return local_word_list\n",
    "\n",
    "#Creates a dictionary similar to word_split, but for full data set\n",
    "def local_word_dict(text_list):\n",
    "    local_word_dict = {}\n",
    "    for i in range(len(text_list)):\n",
    "        word_dict = word_split(text_list.iloc[i])\n",
    "        local_word_dict = {word: local_word_dict.get(word, 0) + word_dict.get(word, 0) for word in set(local_word_dict)|set(word_dict)}\n",
    "    return local_word_dict\n",
    "\n",
    "#Returns the n most frequent words in a dictionary of the type described in word_split\n",
    "def top_words(n, word_dict):\n",
    "    assert n < len(word_dict)\n",
    "    top_dict = {}\n",
    "    sorted_keys = sorted(word_dict, key=word_dict.get, reverse=True)\n",
    "    for i in range(n):\n",
    "        top_dict[sorted_keys[i]] = word_dict[sorted_keys[i]]\n",
    "    return top_dict\n",
    "        \n",
    "#Applying the functions to different subsets of the data            \n",
    "emails = train_data.text\n",
    "all_words = local_words(emails)\n",
    "\n",
    "spam = train_data.text[train_data.spam > 0]\n",
    "spam_words = local_words(spam)\n",
    "\n",
    "non_spam = train_data.text[train_data.spam < 1]\n",
    "non_spam_words = local_words(non_spam)\n",
    "\n",
    "email_dict = local_word_dict(emails)\n",
    "\n",
    "spam_dict = local_word_dict(spam)\n",
    "\n",
    "non_spam_dict = local_word_dict(non_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reading external data into files. Dictionary, names, other custom lists\n",
    "\n",
    "english_dict_file = os.path.join(dict_path, 'words_dictionary.json')\n",
    "with open(english_dict_file,\"r\") as english_dictionary:\n",
    "    english_words_dict = json.load(english_dictionary)\n",
    "english_words_set = set(english_words_dict.keys())\n",
    "\n",
    "english_fnames_file = os.path.join(name_path, 'popular-both-first.txt')\n",
    "first_names = pd.read_csv(english_fnames_file, header=None)\n",
    "english_fnames_list = first_names.iloc[:, 0]\n",
    "english_fnames_list = [english_fnames_list[i].lower() for i in range(len(english_fnames_list))\n",
    "                      if isinstance(english_fnames_list[i], str)]\n",
    "english_fname_set = set(english_fnames_list)\n",
    "\n",
    "english_lnames_file = os.path.join(name_path, 'census-dist-2500-last.csv')\n",
    "last_names = pd.read_csv(english_lnames_file, header=None)\n",
    "english_lnames_list = last_names.iloc[:, 0]\n",
    "english_lnames_list = [english_lnames_list[i].lower() for i in range(len(english_lnames_list))\n",
    "                      if isinstance(english_lnames_list[i], str)]\n",
    "english_lname_set = set(english_lnames_list)\n",
    "\n",
    "english_greetings_file = os.path.join(additional_path, 'greetings.txt')\n",
    "greetings = pd.read_csv(english_greetings_file, header=None)\n",
    "greetings_list = greetings.iloc[:, 0]\n",
    "greetings_set = set(greetings_list)\n",
    "\n",
    "indicator_file = os.path.join(additional_path, 'indicators.txt')\n",
    "indicators = pd.read_csv(indicator_file, header=None)\n",
    "indicators_list = indicators.iloc[:, 0]\n",
    "indicators_set = set(indicators_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting proportion of correct words\n",
    "def text_dict_check(text_dict, english_dict_set):\n",
    "    correct_words = 0\n",
    "    incorrect_words = 0\n",
    "    text_set = set(text_dict.keys())\n",
    "    for word in text_set:\n",
    "        if word in english_dict_set:\n",
    "            correct_words += 1\n",
    "    return correct_words/len(text_dict)\n",
    "\n",
    "non_spam_prop = np.mean(np.array([text_dict_check(word_split(non_spam.iloc[i]), english_words_set)\n",
    "                                  for i in range(len(non_spam))]))\n",
    "spam_prop = np.mean(np.array([text_dict_check(word_split(spam.iloc[i]), english_words_set)\n",
    "                              for i in range(len(spam))]))\n",
    "\n",
    "#Check dictionary for words also in set\n",
    "def personal_names_check(text_dict, english_name_set):\n",
    "    personal_names = 0\n",
    "    text_set = set(text_dict.keys())\n",
    "    for word in text_set:\n",
    "        if word in english_name_set:\n",
    "            personal_names += 1\n",
    "    return personal_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Collecting all features in a numpy array\n",
    "def create_design_matrix(data, english_dict_set, english_name_set):\n",
    "    features = 6\n",
    "    observations = len(data)\n",
    "    X = np.zeros((observations, features))\n",
    "    for i in range(observations):\n",
    "        mail = data.text.iloc[i]\n",
    "        d = word_split(mail)\n",
    "        #Proportion of unique words\n",
    "        X[i, 0] = len(d)/sum(d.values())\n",
    "        #Proportion correct words\n",
    "        X[i, 1] = text_dict_check(d, english_words_set)\n",
    "        #Number of personal names\n",
    "        X[i, 2] = personal_names_check(d, english_fname_set)\n",
    "        #Number of last names\n",
    "        X[i, 3] = personal_names_check(d, english_lname_set)\n",
    "        #Number of greetings\n",
    "        X[i, 4] = personal_names_check(d, greetings_set)\n",
    "        #Number of indicators\n",
    "        X[i, 5] = personal_names_check(d, indicators_set)\n",
    "    return X\n",
    "\n",
    "#Creating numpy array for response\n",
    "def create_response_vector(data):\n",
    "    Y = np.array(data.spam)\n",
    "    Y[Y == 0] = -1\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846433990895\n",
      "0.828358208955\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def data_split(data):\n",
    "    test_indices = np.random.choice(len(data), len(data)//5)\n",
    "    train_indices = np.array([i for i in range(len(data)) if i not in test_indices])\n",
    "    Y = create_response_vector(data)\n",
    "    X = create_design_matrix(data, english_words_set, english_name_set)\n",
    "    X_train = X[train_indices]\n",
    "    Y_train = Y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    Y_test = Y[test_indices]\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = data_split(train_data)\n",
    "lr = LogisticRegression().fit(X_train, Y_train)\n",
    "print(lr.score(X_train, Y_train))\n",
    "print(lr.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86170212766\n",
      "0.856965174129\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC, NuSVC\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = data_split(train_data)\n",
    "svm = NuSVC(nu=0.3).fit(X_train, Y_train)\n",
    "print(svm.score(X_train, Y_train))\n",
    "print(svm.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.900243309002\n",
      "0.874378109453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = data_split(train_data)\n",
    "tree = DecisionTreeClassifier(max_depth=8, random_state=0)\n",
    "tree.fit(X_train, Y_train)\n",
    "print(tree.score(X_train, Y_train))\n",
    "print(tree.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986047922354\n",
      "0.866915422886\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train, X_test, Y_train, Y_test = data_split(train_data)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "forest.fit(X_train, Y_train)\n",
    "print(forest.score(X_train, Y_train))\n",
    "print(forest.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
